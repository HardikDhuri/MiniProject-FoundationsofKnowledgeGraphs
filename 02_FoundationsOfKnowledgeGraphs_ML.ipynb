{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b06aec-0b40-4c7b-8039-73a17aef9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdflib import Graph, URIRef, RDF\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200310e6-e87e-4cca-b91a-5ba836168aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.getcwd()\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\");\n",
    "\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"KG-2022-train.nt\")\n",
    "TEST_FILE  = os.path.join(DATA_DIR, \"KG-2022-test.nt\")\n",
    "RESULT_FILE = os.path.join(PROJECT_ROOT, \"result_ml.ttl\")\n",
    "\n",
    "TRUTH_PRED_URI = URIRef(\"http://swc2017.aksw.org/hasTruthValue\")\n",
    "TRUTH_PRED_STR = \"http://swc2017.aksw.org/hasTruthValue\"\n",
    "XSD_DOUBLE_URI = \"http://www.w3.org/2001/XMLSchema#double\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "609e4628-c490-4fe5-858b-12cf65908484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fact_dataset(path: str, with_labels: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a reified fact dataset from an N-Triples file.\n",
    "\n",
    "    Each fact is an rdf:Statement with:\n",
    "      - rdf:subject\n",
    "      - rdf:predicate\n",
    "      - rdf:object\n",
    "      - optionally: swc2017:hasTruthValue (float label in [0, 1])\n",
    "\n",
    "    Returns a DataFrame with columns:\n",
    "      - fact_uri\n",
    "      - subject\n",
    "      - predicate\n",
    "      - object\n",
    "      - truth (float, if with_labels=True)\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Loading dataset from {path}\")\n",
    "    g = Graph()\n",
    "    g.parse(path, format=\"nt\")\n",
    "    print(f\"[INFO] Parsed {len(g)} RDF triples\")\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for fact in g.subjects(RDF.type, RDF.Statement):\n",
    "        s = g.value(fact, RDF.subject)\n",
    "        p = g.value(fact, RDF.predicate)\n",
    "        o = g.value(fact, RDF.object)\n",
    "\n",
    "        if s is None or p is None or o is None:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"fact_uri\": str(fact),\n",
    "            \"subject\": str(s),\n",
    "            \"predicate\": str(p),\n",
    "            \"object\": str(o),\n",
    "        }\n",
    "\n",
    "        if with_labels:\n",
    "            truth_literal = g.value(fact, TRUTH_PRED_URI)\n",
    "            if truth_literal is None:\n",
    "                # training instances without labels are skipped\n",
    "                continue\n",
    "            row[\"truth\"] = float(truth_literal)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"[INFO] Facts loaded: {df.shape[0]} rows\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "495924f4-bbf4-47c0-b0fe-cf3e21d6bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(train: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Compute frequency and count statistics from the training data.\n",
    "\n",
    "    Returns a dict with:\n",
    "      - overall_prior\n",
    "      - freq_predicate, cnt_predicate\n",
    "      - freq_sp,        cnt_sp\n",
    "      - freq_po,        cnt_po\n",
    "      - deg_subject,    deg_object\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    train = train.copy()\n",
    "    train[\"truth\"] = train[\"truth\"].astype(float)\n",
    "\n",
    "    stats[\"overall_prior\"] = train[\"truth\"].mean()\n",
    "\n",
    "    def freq_and_count(keys):\n",
    "        pos = defaultdict(float)\n",
    "        tot = defaultdict(float)\n",
    "        for _, row in train.iterrows():\n",
    "            k = tuple(row[k] for k in keys)\n",
    "            pos[k] += row[\"truth\"]\n",
    "            tot[k] += 1.0\n",
    "        # Laplace smoothing: (pos + 1) / (tot + 2)\n",
    "        freq = {k: (pos[k] + 1.0) / (tot[k] + 2.0) for k in tot}\n",
    "        return freq, tot\n",
    "\n",
    "    # per predicate\n",
    "    freq_predicate, cnt_predicate = freq_and_count([\"predicate\"])\n",
    "    # per (subject, predicate)\n",
    "    freq_sp, cnt_sp = freq_and_count([\"subject\", \"predicate\"])\n",
    "    # per (predicate, object)\n",
    "    freq_po, cnt_po = freq_and_count([\"predicate\", \"object\"])\n",
    "\n",
    "    stats[\"freq_predicate\"] = freq_predicate\n",
    "    stats[\"cnt_predicate\"]  = cnt_predicate\n",
    "    stats[\"freq_sp\"]        = freq_sp\n",
    "    stats[\"cnt_sp\"]         = cnt_sp\n",
    "    stats[\"freq_po\"]        = freq_po\n",
    "    stats[\"cnt_po\"]         = cnt_po\n",
    "\n",
    "    # degrees of subjects and objects (how often they appear)\n",
    "    deg_subject = defaultdict(int)\n",
    "    deg_object  = defaultdict(int)\n",
    "    for _, row in train.iterrows():\n",
    "        deg_subject[row[\"subject\"]] += 1\n",
    "        deg_object[row[\"object\"]]  += 1\n",
    "\n",
    "    stats[\"deg_subject\"] = deg_subject\n",
    "    stats[\"deg_object\"]  = deg_object\n",
    "\n",
    "    print(f\"[INFO] Stats computed. Overall prior truth: {stats['overall_prior']:.4f}\")\n",
    "    return stats\n",
    "\n",
    "\n",
    "def _get_or_default(d, key, default):\n",
    "    return float(d[key]) if key in d else float(default)\n",
    "\n",
    "\n",
    "def features_for_row(row: pd.Series, stats: dict) -> list[float]:\n",
    "    \"\"\"\n",
    "    Construct the feature vector for a single fact.\n",
    "    \"\"\"\n",
    "    p = row[\"predicate\"]\n",
    "    s = row[\"subject\"]\n",
    "    o = row[\"object\"]\n",
    "\n",
    "    # base frequencies\n",
    "    f_pred = _get_or_default(stats[\"freq_predicate\"], (p,), stats[\"overall_prior\"])\n",
    "    f_sp   = _get_or_default(stats[\"freq_sp\"],        (s, p), f_pred)\n",
    "    f_po   = _get_or_default(stats[\"freq_po\"],        (p, o), f_pred)\n",
    "\n",
    "    # counts / supports\n",
    "    c_pred = _get_or_default(stats[\"cnt_predicate\"], (p,), 0.0)\n",
    "    c_sp   = _get_or_default(stats[\"cnt_sp\"],        (s, p), 0.0)\n",
    "    c_po   = _get_or_default(stats[\"cnt_po\"],        (p, o), 0.0)\n",
    "\n",
    "    # degrees\n",
    "    deg_s = _get_or_default(stats[\"deg_subject\"], s, 0.0)\n",
    "    deg_o = _get_or_default(stats[\"deg_object\"],  o, 0.0)\n",
    "\n",
    "    return [\n",
    "        f_pred,   # 0 frequency per predicate\n",
    "        f_sp,     # 1 frequency per (subject, predicate)\n",
    "        f_po,     # 2 frequency per (predicate, object)\n",
    "        c_pred,   # 3 count per predicate\n",
    "        c_sp,     # 4 count per (subject, predicate)\n",
    "        c_po,     # 5 count per (predicate, object)\n",
    "        deg_s,    # 6 degree of subject\n",
    "        deg_o     # 7 degree of object\n",
    "    ]\n",
    "\n",
    "\n",
    "def make_feature_matrix(df: pd.DataFrame, stats: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build the feature matrix X for all rows in df.\n",
    "    \"\"\"\n",
    "    X = np.vstack([features_for_row(row, stats) for _, row in df.iterrows()])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac5ac1cb-23b5-4544-9e39-d536653cd41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_model(train_df: pd.DataFrame, stats: dict):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on engineered features.\n",
    "    Returns the fitted sklearn Pipeline.\n",
    "    \"\"\"\n",
    "    X_train = make_feature_matrix(train_df, stats)\n",
    "    y_train = train_df[\"truth\"].astype(float).values\n",
    "\n",
    "    print(\"[INFO] Training Logistic Regression model...\")\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                penalty=\"l2\",\n",
    "                C=1.0,\n",
    "                solver=\"lbfgs\",\n",
    "                max_iter=1000\n",
    "            ))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    proba_train = pipeline.predict_proba(X_train)[:, 1]\n",
    "    auc = roc_auc_score(y_train, proba_train)\n",
    "    print(f\"[INFO] Training ROC AUC (LogReg): {auc:.4f}\")\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def score_test_set(test_df: pd.DataFrame, stats: dict, model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply the trained model to the test set and return a DataFrame\n",
    "    with 'fact_uri' and 'score' columns.\n",
    "    \"\"\"\n",
    "    X_test = make_feature_matrix(test_df, stats)\n",
    "    proba_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    out = test_df[[\"fact_uri\"]].copy()\n",
    "    out[\"score\"] = proba_test.astype(float)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea38277-24d8-43b7-82cd-de8da328d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_result_ttl(scored_df: pd.DataFrame, path: str):\n",
    "    \"\"\"\n",
    "    Write a GERBIL-compatible TTL file:\n",
    "\n",
    "      <Fact-URI> <http://swc2017.aksw.org/hasTruthValue> \"value\"^^<http://www.w3.org/2001/XMLSchema#double> .\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Writing result file to {path}\")\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in scored_df.iterrows():\n",
    "            fact_uri = row[\"fact_uri\"]\n",
    "            val = float(row[\"score\"])\n",
    "            line = (\n",
    "                f\"<{fact_uri}> \"\n",
    "                f\"<{TRUTH_PRED_STR}> \"\n",
    "                f\"\\\"{val:.6f}\\\"^^<{XSD_DOUBLE_URI}> .\\n\"\n",
    "            )\n",
    "            f.write(line)\n",
    "    print(\"[INFO] Finished writing result file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f685858-f775-478d-b397-5f1dce2ee8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os.path.exists(TRAIN_FILE):\n",
    "        raise FileNotFoundError(f\"Training file not found: {TRAIN_FILE}\")\n",
    "    if not os.path.exists(TEST_FILE):\n",
    "        raise FileNotFoundError(f\"Test file not found: {TEST_FILE}\")\n",
    "\n",
    "    # 1) Load data\n",
    "    train_df = load_fact_dataset(TRAIN_FILE, with_labels=True)\n",
    "    test_df  = load_fact_dataset(TEST_FILE,  with_labels=False)\n",
    "\n",
    "    # 2) Compute statistics for feature engineering\n",
    "    stats = compute_stats(train_df)\n",
    "\n",
    "    # 3) Train ML model\n",
    "    model = train_ml_model(train_df, stats)\n",
    "\n",
    "    # 4) Score test set\n",
    "    scored_test = score_test_set(test_df, stats, model)\n",
    "    print(\"[INFO] Example scores:\")\n",
    "    print(scored_test.head())\n",
    "\n",
    "    # 5) Write GERBIL-compatible TTL\n",
    "    write_result_ttl(scored_test, RESULT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4f9236-e389-405e-b53c-b123c0942b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading dataset from /Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/data/KG-2022-train.nt\n",
      "[INFO] Parsed 6170 RDF triples\n",
      "[INFO] Facts loaded: 1234 rows\n",
      "[INFO] Loading dataset from /Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/data/KG-2022-test.nt\n",
      "[INFO] Parsed 5368 RDF triples\n",
      "[INFO] Facts loaded: 1342 rows\n",
      "[INFO] Stats computed. Overall prior truth: 0.5470\n",
      "[INFO] Training Logistic Regression model...\n",
      "[INFO] Training ROC AUC (LogReg): 0.9736\n",
      "[INFO] Example scores:\n",
      "                                        fact_uri     score\n",
      "0  http://swc2017.aksw.org/task2/dataset/3417193  0.962194\n",
      "1  http://swc2017.aksw.org/task2/dataset/3812648  0.042155\n",
      "2  http://swc2017.aksw.org/task2/dataset/3883848  0.997382\n",
      "3  http://swc2017.aksw.org/task2/dataset/3613044  0.942811\n",
      "4  http://swc2017.aksw.org/task2/dataset/3820276  0.998952\n",
      "[INFO] Writing result file to /Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/result_ml.ttl\n",
      "[INFO] Finished writing result file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/codex/Code/course-work/fokg/MiniProject-FoundationsofKnowledgeGraphs/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedbc26-5415-4dc0-af57-2a1971f1ac17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
